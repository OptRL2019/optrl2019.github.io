---
title: 'NeurIPS 2019 Optimization Foundations for Reinforcement Learning Workshop'
layout: default
---

# Schedule

| Time | Event |
| ---- | ----- |
| 08:00 - 08:10 | Opening Remarks |
| 08:10 - 08:50 | **Invited Talk** - [Mengdi Wang][mengdi]: *TBA*|
| 08:50 - 09:10 | **Contributed Talk** - Lior Shani, Yonathan Efroni, Shie Mannor: *Adaptive Trust Region Policy Optimization: Convergence and Faster Rates of regularized MDPs*|
| 09:10 - 09:30 | **Spotlight** |
| 09:30 - 10:30 | **Poster and Coffee Break** |
| 10:30 - 11:10 | **Invited Talk** - [Sham Kakade][sham]: *The Provable Effectiveness of Policy Gradient Methods in Reinforcement Learning*|
| 11:10 - 11:30 | **Contributed Talk** - Naman Agarwal, Elad Hazan, Karan Singh: *Logarithmic Regret for Online Control*|
| 11:30 - 12:10 | **Spotlight** |
| 12:10 - 14:00 | **Lunch** |
| 14:00 - 14:40 | **Invited Talk** - [Benjamin Van Roy][ben]: *TBA*|
| 14:40 - 15:20 | **Invited Talk** - [Shipra Agrawal][shipra]: *Learning in structured MDPs with convex cost function: improved regret bounds for inventory management*|
| 15:20 - 16:20 | **Poster and Coffee Break** |
| 16:20 - 17:00 | **Invited Talk** - [Huizhen Yu][huizhen]: *On the Convergence of GTD($\lambda$) with General $\lambda$* |
| 17:00 - 17:20 | **Contributed Talk**- Jonathan Lee, Ching-An Cheng, Ken Goldberg, Byron Boot: *Continuous Online Learning and New Insights to Online Imitation Learning* |
| 17:20 - 17:45 | **Panel Discussion** - [Richard Sutton][rich], [Doina Precup][doina] |
| 17:45 - 18:00 | **Closing Remarks** |

<!-- [speakers]: #speakers -->
[sham]: https://homes.cs.washington.edu/~sham/
[shipra]: http://www.columbia.edu/~sa3305/
[ben]: https://web.stanford.edu/~bvr/
[mengdi]: https://mwang.princeton.edu/
[huizhen]: https://directory.ualberta.ca/person/huizhen
[rich]: http://incompleteideas.net/
[doina]: https://www.cs.mcgill.ca/~dprecup/

