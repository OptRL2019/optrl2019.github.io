---
title: 'NeurIPS 2019 Optimization Foundations for Reinforcement Learning Workshop'
layout: default
---


# Accepted Papers

We have received many high-quality submissions. Thanks to all the contributors for the supports.

<!-- The order below is random. 
Some papers will be selected to give an additional oral/spotlight presentation, which will be announced soon. -->

## Oral presentation
- <a href="assets/accepted_papers/2.pdf">**Adaptive Trust Region Policy Optimization: Convergence and Faster Rates of regularized MDPs**</a>. Lior Shani, Yonathan Efroni, Shie Mannor
- <a href="assets/accepted_papers/37.pdf">**Logarithmic Regret for Online Control**</a>. Naman Agarwal, Elad Hazan, Karan Singh	
- <a href="assets/accepted_papers/55.pdf">**Continuous Online Learning and New Insights to Online Imitation Learning**</a>. Jonathan Lee, Ching-An Cheng, Ken Goldberg, Byron Boots

## Spotlight
- <a href="assets/accepted_papers/7.pdf">**Geometric Insights into the Convergence of Nonlinear TD Learning**</a>. David Brandfonbrener, Joan Bruna
- <a href="assets/accepted_papers/10.pdf">**Apprenticeship Learning via Frank-Wolfe**</a>.  Tom Zahavy, Haim Kaplan, Alon Cohen, Yishay Mansour	
- <a href="assets/accepted_papers/22.pdf">**Empirical Likelihood for Contextual Bandits**</a>. Nikos Karampatziakis, John Langford, Paul Mineiro.
- <a href="assets/accepted_papers/27.pdf">**Analysis of Q-Learning: Switching System Approach**</a>. Donghwan Lee, Niao He
-  <a href="assets/accepted_papers/33.pdf">**Solving Discounted Stochastic Two-Player Games with Near-Optimal Time and Sample Complexity**</a>. Aaron Sidford, Mengdi Wang, Lin Yang, Yinyu Ye
- <a href="assets/accepted_papers/42.pdf">**Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games**</a>. Zuyue Fu, Zhuoran Yang, Yongxin Chen, Zhaoran Wang
- <a href="assets/accepted_papers/44.pdf">**ALGAE: Policy Gradient from Arbitrary Experience**</a>.	Ofir Nachum, Bo Dai, Ilya  Kostrikov, Dale  Schuurmans
- <a href="assets/accepted_papers/48.pdf">**Harnessing Infinite-Horizon Off-Policy Evaluation: Double Robustness via Duality**</a>. Ziyang Tang, Yihao Feng, Lihong Li, Denny Zhou, Qiang Liu
- <a href="assets/accepted_papers/49.pdf">**Learning Reward Machines for Partially Observable Reinforcement Learning**</a>. Rodrigo A Toro Icarte, Ethan Waldie, Toryn  Klassen,  Richard Valenzano, Margarita  Castro, Sheila A.  McIlraith	
- <a href="assets/accepted_papers/53.pdf">**Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?**</a>. Simon Du, Sham Kakade, Ruosong Wang, Lin Yang
- <a href="assets/accepted_papers/54.pdf">**On Computation and Generalization of Generative Adversarial Imitation Learning**</a>. Minshuo Chen, Yizhou Wang, Tianyi  Liu, Xingguo Li, Zhuoran Yang, Zhaoran Wang, Tuo Zhao
- <a href="assets/accepted_papers/69.pdf">**A Distributional Analysis of Sampling-Based Reinforcement Learning Algorithms**</a>. Philip Amortila, Doina Precup, Prakash  Panangaden, Marc G. Bellemare	

## Poster

- <a href="assets/accepted_papers/17.pdf">**Kalman Optimization for Value Approximation**</a>. Shirli Di-Castro, Shie Mannor
- <a href="assets/accepted_papers/51.pdf">**Hierarchical model-based policy optimization: from actions to action sequences and back**</a>. Daniel McNamee
- <a href="assets/accepted_papers/35.pdf">**Improving Evolutionary Strategies With Past Descent Directions**</a>. Asier Mujika, Florian Meier, Marcelo Matheus Gauy, Angelika Steger
- **ISL: Optimal Policy Learning With Optimal Exploration-Exploitation Trade-Off**. Lucas C Cassano, Ali H Sayed
- <a href="assets/accepted_papers/13.pdf">**Provably Convergent Off-Policy Actor-Critic with Function Approximation**</a>. Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson
- <a href="assets/accepted_papers/18.pdf">**Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP**</a>.	Kefan Dong, Yuanhao Wang, Xiaoyu Chen, Liwei Wang
- <a href="assets/accepted_papers/21.pdf">**Adaptive Smoothing Path Integral Control**</a>. Dominik Thalmeier, Bert Kappen, Simone Totaro, Vicenç Gómez
- <a href="assets/accepted_papers/65.pdf">**Data Efficient Training for Reinforcement Learning with Adaptive Behavior Policy Sharing**</a>. Ge Liu, Heng-Tze Cheng, Rui  Wu, Jing  Wang, Jayiden Ooi, Ang Li, Sibon Li, Lihong Li, Craig Boutilier
- <a href="assets/accepted_papers/11.pdf">**A Two Time-Scale Update Rule Ensuring Convergence of Episodic Reinforcement Learning Algorithms at the Example of RUDDER**</a>. Markus 	Holzleitner, José Arjona-Medina, Marius-Constantin  Dinu, Sepp  Hochreiter
- <a href="assets/accepted_papers/34.pdf">**Distributional Reinforcement Learning for Energy-Based Sequential Models**</a>. Tetiana Parshakova, Jean-Marc Andreoli, Marc Dymetman
- <a href="assets/accepted_papers/16.pdf">**Multi-Task Reinforcement Learning without Interference**</a>. Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Karol Hausman, Sergey Levine, Chelsea Finn
- <a href="assets/accepted_papers/73.pdf">**Toward Provably Unbiased Temporal-Difference Value Estimation**</a>. Roy Fox
- <a href="assets/accepted_papers/60.pdf">**Provable Q-Iteration without Concentrability**</a>. Ming Yu, Zhuoran Yang, Mengdi Wang, Zhaoran Wang
- **Faster saddle-point optimization for solving large-scale Markov decision processes**. Joan Bas Serrano, Gergely Neu
- <a href="assets/accepted_papers/45.pdf">**Approximate information state for partially observed systems**</a>. Jayakumar Subramanian, Aditya Mahajan
- **Improved Upper and Lower Bounds for Policy and Strategy Iteration**. Aaron Sidford, Mengdi Wang, Lin  Yang, Yinyu Ye
- **Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound**. Lin Yang, Mengdi Wang
- <a href="assets/accepted_papers/8.pdf">**Deterministic Bellman Residual Minimization**</a>. Ehsan Saleh, Nan Jiang,
- <a href="assets/accepted_papers/36.pdf">**Reinforcement Learning with Langevin Dynamics**</a>. Parameswaran Kamalaruban, Doga Tekin, Paul Rolland, Volkan Cevher
- **Provably Efficient Reinforcement Learning with Linear Function Approximation**. Chi Jin, Zhuoran Yang, Zhaoran Wang, Michael Jordan
- <a href="assets/accepted_papers/43.pdf">**On the Finite-Time Convergence of Actor-Critic Algorithm**</a>.	Shuang Qiu, Zhuoran Yang, Jieping Ye, Zhaoran Wang
- <a href="assets/accepted_papers/67.pdf">**Approximability Gap between Model-based and Model-free Algorithms in Continuous State Space**</a>. Kefan Dong, Yuping Luo, Tengyu Ma
- <a href="assets/accepted_papers/15.pdf">**Entropy Regularization with Discounted Future State Distribution in Policy Gradient Methods**</a>. Riashat Islam, Raihan Seraj, Pierre-Luc Bacon, Doina Precup,
- <a href="assets/accepted_papers/75.pdf">**Batch and Sequential Policy Optimization with Doubly Robust Objectives**</a>. Alex P Lewandowski, Dale Schuurmans
- **A Single Time-scale Stochastic Approximation Method for Nested Stochastic Optimization**. Saeed Ghadimi, Andrzej Ruszczynski, Mengdi Wang
- <a href="assets/accepted_papers/63.pdf">**CAQL: Continuous Action Q-Learning**</a>. Yinlam Chow, Moonkyung Ryu, Craig Boutilier, Ross Anderson, Christian Tjandraatmadja 
- **The Gambler's Problem and Beyond**. Baoxiang Wang, Shuai  Li, Jiajin Li, Siu	On
- <a href="assets/accepted_papers/52.pdf">**Toward Understanding Catastrophic Interference in Online Reinforcement Learning**</a>. Vincent Liu, Hengshuai Yao, Martha White
- **Optimistic Adaptive Gradient Methods**. Xinyi Chen, Simon Du, Elad Hazan
- <a href="assets/accepted_papers/38.pdf">**QNTRPO: Including Curvature in TRPO**</a>. Devesh K Jha, Arvind U Raghunathan, Diego Romeres
- **Selectively Planning with Imperfect Models via Learned Error Signals**. Muhammad Zaheer, Samuel Sokota, Erin Talvitie, Martha White
- <a href="assets/accepted_papers/6.pdf">**A Stochastic Derivative Free Optimization Method with Momentum**</a>. Eduard Gorbunov, Adel Bibi, Ozan Sener, El Houcine Bergou, Peter Richtarik
<!-- <a href="assets/accepted_papers/42.pdf">**Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games**</a>. Zuyue Fu, Zhuoran Yang, Yongxin Chen, Zhaoran Wang-->
- <a href="assets/accepted_papers/29.pdf">**Trajectory-wise Control Variates for Variance Reduction in Policy Gradient Methods**</a>. Xinyan Yan, Ching-An Cheng, Byron Boots
- <a href="assets/accepted_papers/62.pdf">**Analyzing the Variance of Policy Gradient Estimators for the Linear-Quadratic Regulator**</a>. James Preiss, Chen-Yu Wei, Sébastien Arnold, Marius Kloft
- <a href="assets/accepted_papers/3.pdf">**Sample Efficient Policy Gradient Methods with Recursive Variance Reduction**</a>. Pan Xu, Xi Gao, Quanquan Gu
- <a href="assets/accepted_papers/70.pdf">**A Lagrangian Method for Inverse Problems in Reinforcement Learning**</a>. Pierre-Luc Bacon, Florian T Schaefer, Clement Gehring, Animashree Anandkumar, Emma Brunskill
- <a href="assets/accepted_papers/19.pdf">**Policy Continuation and Policy Evolution with Hindsight Inverse Dynamics**</a>. Hao Sun, Bo Dai, Zhizhong Li, Xiaotong Liu, Rui  Xu, Dahua Lin, Bolei Zhou
- <a href="assets/accepted_papers/25.pdf">**Observational Overfitting in Reinforcement Learning**</a>. Xingyou Song, YiDing Jiang, Yilun Du, Behnam Neyshabur
- <a href="assets/accepted_papers/71.pdf">**Compatible features for Monotonic Policy Improvement**</a>. Marcin B Tomczak, Sergio Valcarcel Macua, Enrique Munoz De Cote, Peter Vrancx
- <a href="assets/accepted_papers/41.pdf">**On the Convergence of Approximate and Regularized Policy Iteration Schemes**</a>. Elena Smirnova, Elvis Dohmatob
- **An Asynchronous Multi-Agent Actor-Critic Algorithm for Distributed Reinforcement Learning**. Yixuan Lin, Yuehan Luo, Wesley Suttle, Kaiqing Zhang, Zhuoran Yang, Zhaoran  Wang, Tamer Basar, Romeil Sandhu, Ji Liu
- <a href="assets/accepted_papers/20.pdf">**Revisit Policy Optimization in Matrix Form**</a>. Sitao Luan, Xiao-Wen Chang, Doina Precup
- **A Finite Time Analysis of Temporal Difference Learning With Linear Function Approximation**. Jalaj Bhandari, Daniel Russo
- **Global Optimality Guarantees For Policy Gradient Methods**. Jalaj Bhandari, Daniel Russo
- <a href="assets/accepted_papers/39.pdf">**On the Sample Complexity of Actor-Critic for Reinforcement Learning**</a>. Harshat Kumar, Alec Koppel, Alejandro Ribeiro
- <a href="assets/accepted_papers/1.pdf">**Adaptive Discretization for Episodic Reinforcement Learning in Metric Spaces**</a>. Siddhartha Banerjee, Sean Sinclair, Christina Lee Yu
- <a href="assets/accepted_papers/5.pdf">**Fast multi-agent temporal-difference learning via homotopy stochastic primal-dual method**</a>. Dongsheng Ding, Xiaohan Wei, Zhuoran Yang, Zhaoran Wang, Mihailo Jovanovic
- <a href="assets/accepted_papers/50.pdf">**Performance of Q-learning with Linear Function Approximation: Stability and Finite Time Analysis**</a>. Zaiwei Chen, Sheng Zhang, Thinh T Doan, Siva Theja Maguluri, John-Paul Clarke
- <a href="assets/accepted_papers/14.pdf">**Feature-Based Q-Learning for Two-Player Stochastic Games**</a>. Zeyu Jia, Lin Yang, Mengdi Wang
- **A Convergence Result for Regularized Actor-Critic Methods**. Wesley Suttle, Zhuoran  Yang, Kaiqing Zhang, Ji Liu
- **Neural Policy Gradient Methods: Global Optimality and Rates of Convergence**. Lingxiao Wang, Qi Cai, Zhuoran Yang
- <a href="assets/accepted_papers/72.pdf">**All-Action Policy Gradient Methods: A Numerical Integration Approach**</a>. Benjamin Petit, Loren Amdahl-Culleton, Yao Liu, Jimmy Smith, Pierre-Luc Bacon
- <a href="assets/accepted_papers/40.pdf">**On Connections between Constrained Optimization and Reinforcement Learning**</a>. Nino Vieillard, Olivier Pietquin, Matthieu Geist
- <a href="assets/accepted_papers/24.pdf">**Worst-Case Regret Bound for Perturbation Based Exploration in Reinforcement Learning**</a>. Ziping Xu, Ambuj Tewari
- <a href="assets/accepted_papers/68.pdf">**Generalized Policy Updates for Policy Optimization**</a>. Saurabh Kumar, Robert Dadashi, Zafarali Ahmed, Dale Schuurmans, Marc G. Bellemare
- <a href="assets/accepted_papers/74.pdf">**Stochastic convex optimization for provably efficient apprenticeship learning**</a>.  Angeliki Kamoutsi, Angeliki Kamoutsi, Goran Banjac, and John Lygeros
- <a href="assets/accepted_papers/66.pdf">**Discounted Reinforcement Learning is Not an Optimization Problem**</a>. Abhishek Naik, Roshan Shariff, Niko Yasui, Richard Sutton

